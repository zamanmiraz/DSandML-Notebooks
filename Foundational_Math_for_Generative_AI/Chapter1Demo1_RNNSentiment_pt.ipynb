{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXn3a9h4Bu5orasDOK7ghi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zamanmiraz/DSandML-Notebooks/blob/main/Foundational_Math_for_Generative_AI/Chapter1Demo1_RNNSentiment_pt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUXyqlUmcwpC",
        "outputId": "9b4833ce-6e25-4a02-9df4-f573b66b6919"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n",
            "\u001b[33mWARNING: Skipping torch as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchtext as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torch==2.3.0\n",
            "  Using cached torch-2.3.0-cp312-cp312-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting torchtext==0.18.0\n",
            "  Using cached torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (4.15.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.3.0) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0) (2.32.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchtext==0.18.0) (1.26.4)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.3.0) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.18.0) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.3.0) (1.3.0)\n",
            "Using cached torch-2.3.0-cp312-cp312-manylinux1_x86_64.whl (779.1 MB)\n",
            "Using cached torchtext-0.18.0-cp312-cp312-manylinux1_x86_64.whl (2.0 MB)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m577.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchtext\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.3.0 which is incompatible.\n",
            "torchvision 0.23.0+cu126 requires torch==2.8.0, but you have torch 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.3.0 torchtext-0.18.0\n"
          ]
        }
      ],
      "source": [
        "! pip install gensim\n",
        "! pip uninstall torch torchtext -y\n",
        "! pip install torch==2.3.0 torchtext==0.18.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "769JinVVjf6y",
        "outputId": "547bec62-34ca-4547-a4b3-0acfbe007e6d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the dataset from Hugging Face\n",
        "*imdb* dataset features contain 'text' and 'label'"
      ],
      "metadata": {
        "id": "8I1zZ5U_b3RA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset('imdb')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365,
          "referenced_widgets": [
            "a758ccf6558c4f22925c8d7b2f21a57f",
            "628dbacd76434409a85c84e696051b8f",
            "b8f69a5381cf433ba2657f6e1a9b701e",
            "ae582f73c4ba4bcf9541432f7c61c43b",
            "b6eb03c5165e4cc59a4cc9b597b9f594",
            "0d00c3b9eddb4e54afe95bef19a462ea",
            "49b5f898ce5046efbf8ec9f5e1918c98",
            "e1f52c7a1f494a7f9ec6aa08eb737824",
            "7c5b188ecd5946749c9133de0ba1d409",
            "e9c08a4bc27f45c989641a2c486cf356",
            "e0c56e6479a041d8963fc3d6eba69d20",
            "81f5a1f86ddd4935933bb8f90fedec22",
            "7cff393d9b3749c99723eba92cbfdd68",
            "3c1cf6d055694977ab8e5e4dc0a1d5e5",
            "97eaa4b65c88467ebb8feb5e84c03848",
            "68e7d555ac21405ab4c81584ee2b5e76",
            "8058f5bf9db94aadb21fbf309bc92b45",
            "8de5018830164c7989cbb2f3200441dd",
            "9d96d4f7ba274f5ea554a1f24f3e7798",
            "4d21cc5a0659474daf99807de9125667",
            "7416ecf996424fdf937cf74f1ed3cba4",
            "899e301af689445fb33074774d62e291",
            "f4e771fdef3040858181d1a6d388674d",
            "e9b30794469346e58d7b0ee397ace111",
            "b01015c8bbf94f1f97640cf04f151fa3",
            "c23a206771bc4581963bfaa1505d6129",
            "7ff86eb37e074424a014e5e8bd7aaea8",
            "cdfffb7173ab4f858e62ee63b258ab98",
            "dc0fda7174544f6d804a58ee1b0abe77",
            "7cd53518dba540d58f506db86349bfce",
            "76854904c18841b38389a00354dc189f",
            "d2b3b48abeea444a8f78f612c29c5520",
            "f35cb0ea6d05416e9515cd10a574bd18",
            "3007e2389dc645cc8e93634ffe8964f4",
            "d39584d285164d24ad79450ac2dd02d3",
            "40123ab0ad284b5bbd3ab9ae0d3e0374",
            "e99ac569b41f4cc28a154d5ebd82564b",
            "993802a83ff24b559cb4b42707daffe2",
            "3b7eb0b828e94ece95041f3d48b06a28",
            "5b8f05a2fce144a4ba21e81fb435692a",
            "e7b160322f5a42d78cad54e53ad646b9",
            "1eea3a840c6e42729a63af2cc57dc235",
            "52c045bf0a73416183309f384a608812",
            "48dbb028e23048c8b64638d59c66e91a",
            "f5f18ce949414f44a6d074f5697dc867",
            "ec647fc25f424524b8a1e7f6dbbb49d3",
            "5606a31cad4b4072acb4378e41453e5f",
            "4c3c388b99504b98bd5148751a159202",
            "29685f146b0a439eb0dbad149699983f",
            "cc84d35560ca49099780eafb95d04fe1",
            "83e45e303caf434b99dd2a62e8d39e72",
            "73608a96743c4245902fef2e1dc3b9af",
            "c1c94082c6fe47aabf84706ac008ec88",
            "a61afbc26e9c4dcb9eabb1df94e3fac8",
            "391a1366fa55427d8081e9d7fe673a28",
            "6cea5a057c17421a858387e846de5c03",
            "00125a4a7995405284b7735c4a8c39f5",
            "da3b9586257d413cafe3297652f0ebab",
            "05913b941d8a4db4872bfd1c803a317f",
            "93409edb12d647c1b7fc9e918b50ad61",
            "fd49690f5ffc4d79ab7a7d7bcb09ff65",
            "24b897b80842403493170d07e3f5ff74",
            "20a7fff8b2cb4a538dba8ec57a9e6147",
            "d1ae983fb68047f6b78b92ef59c437fb",
            "b6b160e0e8da44ebb72c5d7e6ce31868",
            "c27dcd41bba14520b487444bcbf6ff65",
            "c5945d21b6284fc6bb10586a665ec83c",
            "27c1f39213bc46a3a8c0d006dd7617cb",
            "3ef5bdcf8f2c46cdbcfa4ea46fb12be5",
            "5ace8bebcbea47b784c56092d772f684",
            "f958dc2f243c4b1c9be272bb764f7abc",
            "5dc7dd12304d4133a162e81882255448",
            "05e399c68ed245dab4142ecefe5f3982",
            "883ade84d3bd4e5da92848e97107f6a7",
            "550da3efe2874fd0ae5968a6b853c117",
            "65df7a1cd38948dda2a0bdff1fd4369b",
            "3c350eab05374a878bc09ba0124b8b27"
          ]
        },
        "id": "_xpe3SUEmrvO",
        "outputId": "8f28aaf9-be16-4e1b-a811-6264fe392e22"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a758ccf6558c4f22925c8d7b2f21a57f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plain_text/train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81f5a1f86ddd4935933bb8f90fedec22"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plain_text/test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4e771fdef3040858181d1a6d388674d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plain_text/unsupervised-00000-of-00001.p(…):   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3007e2389dc645cc8e93634ffe8964f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5f18ce949414f44a6d074f5697dc867"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cea5a057c17421a858387e846de5c03"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5945d21b6284fc6bb10586a665ec83c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Train Word2Vec embeddings\n",
        " - *word2Vec* is a model that learns to represents the word as vectors\n",
        " - Similar words end up with similar vectors\n",
        " - Parameters: sentences - a list of tokenized sentences, vector_size - # of dimensions of word vectors (higher dimension leads to heavier to compute), window - how many words before and after a target word to look at, min_count - Ignores word that appear fewer than this number of times, workers - # of cpu core to train\n",
        "\n",
        " ## 2. Create embedding matrix and Turn it into embedding layer"
      ],
      "metadata": {
        "id": "b6YscD0Hd9hu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from collections import Counter\n",
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "\n",
        "# Hyperparameters\n",
        "max_vocab_size = 25000\n",
        "max_seq_len = 50\n",
        "embedding_dim = 150\n",
        "latent_dim = 512\n",
        "output_dim = 2\n",
        "\n",
        "# -------------------------------\n",
        "# 1. Train Word2Vec embeddings\n",
        "# -------------------------------\n",
        "sentences = [text.split() for text in dataset['train']['text']]\n",
        "word2vec_model = Word2Vec(\n",
        "    sentences,\n",
        "    vector_size=embedding_dim,\n",
        "    window=5,\n",
        "    min_count=1,\n",
        "    workers=4\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# 2. Build vocabulary with torchtext\n",
        "# -------------------------------\n",
        "def yield_tokens(sentences):\n",
        "    for sent in sentences:\n",
        "        yield sent\n",
        "\n",
        "# build the vocab\n",
        "vocab = build_vocab_from_iterator(\n",
        "    yield_tokens(sentences),\n",
        "    max_tokens=max_vocab_size,\n",
        "    specials=['<unk>', '<pad>']\n",
        ")\n",
        "\n",
        "# set default index\n",
        "unk_idx = vocab['<unk>']\n",
        "pad_idx = vocab['<pad>']\n",
        "vocab.set_default_index(unk_idx)\n",
        "\n",
        "# -------------------------------\n",
        "# 3. Create embedding matrix\n",
        "# -------------------------------\n",
        "def create_embedding_matrix(vocab, word2vec_model, embedding_dim):\n",
        "    embedding_matrix = np.zeros((len(vocab), embedding_dim))\n",
        "    for word, idx in vocab.get_stoi().items():\n",
        "        if word in word2vec_model.wv:\n",
        "            embedding_matrix[idx] = word2vec_model.wv[word]\n",
        "        else:\n",
        "            embedding_matrix[idx] = np.random.normal(scale=0.6, size=(embedding_dim,))\n",
        "    return embedding_matrix\n",
        "\n",
        "embedding_matrix = create_embedding_matrix(vocab, word2vec_model, embedding_dim)\n",
        "\n",
        "# Convert to torch tensor for nn.Embedding\n",
        "embedding_matrix = torch.tensor(embedding_matrix, dtype=torch.float32)\n",
        "\n",
        "# -------------------------------\n",
        "# 4. Define Embedding Layer\n",
        "# -------------------------------\n",
        "embedding_layer = nn.Embedding.from_pretrained(\n",
        "    embeddings=embedding_matrix,\n",
        "    freeze=False,          # True = keep pretrained fixed, False = allow fine-tuning\n",
        "    padding_idx=pad_idx\n",
        ")\n",
        "\n",
        "print(\"Vocab size:\", len(vocab))\n",
        "print(\"Embedding layer shape:\", embedding_layer.weight.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60qfcG1Pm00r",
        "outputId": "185458d8-a9ab-4379-ede5-79d90a816268"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
            "/usr/local/lib/python3.12/dist-packages/torchtext/utils.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 25000\n",
            "Embedding layer shape: torch.Size([25000, 150])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "139d0cc5",
        "outputId": "72b01abb-a54f-4e72-925b-9a24dc1c8d90"
      },
      "source": [
        "import torch\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Convert the dataset to map-style\n",
        "train_dataset = to_map_style_dataset(dataset['train'])\n",
        "test_dataset = to_map_style_dataset(dataset['test'])\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_text(text):\n",
        "    return text.split()\n",
        "\n",
        "# Numericalization and padding function\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list = [], []\n",
        "    for sample in batch:  # sample is a dict like {'text': ..., 'label': ...}\n",
        "        _text = sample['text']\n",
        "        _label = sample['label']\n",
        "\n",
        "        # Convert label (assumes numeric labels 0/1)\n",
        "        label_list.append(int(_label))\n",
        "\n",
        "        processed_text = torch.tensor(\n",
        "            [vocab[token] for token in tokenize_text(_text)[:max_seq_len]],\n",
        "            dtype=torch.int64\n",
        "        )\n",
        "        text_list.append(processed_text)\n",
        "\n",
        "    # Pad sequences\n",
        "    padded_text_list = torch.nn.utils.rnn.pad_sequence(\n",
        "        text_list, batch_first=True, padding_value=pad_idx\n",
        "    )\n",
        "\n",
        "    return torch.tensor(label_list, dtype=torch.int64), padded_text_list\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_batch\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_batch\n",
        ")\n",
        "\n",
        "print(\"Train DataLoader created.\")\n",
        "print(\"Test DataLoader created.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchtext/data/__init__.py:4: UserWarning: \n",
            "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
            "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
            "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train DataLoader created.\n",
            "Test DataLoader created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, embedding_layer, latent_dim):\n",
        "        super().__init__()\n",
        "        self.embedding = embedding_layer # embedding matrix into embedding layer\n",
        "        self.rnn = nn.RNN( # Input dimension, hidden dimension\n",
        "            embedding_layer.embedding_dim,\n",
        "            latent_dim,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "    def forward(self, text):\n",
        "        # text shape: (batch_size, seq_len)\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded shape: (batch_size, seq_len, embedding_dim)\n",
        "\n",
        "        output, hidden = self.rnn(embedded) # Corrected unpacking\n",
        "        # output shape: (batch_size, seq_len, latent_dim)\n",
        "        # hidden shape: (1, batch_size, latent_dim)\n",
        "\n",
        "        return hidden.squeeze(0)\n",
        "        # returned shape: (batch_size, latent_dim)\n",
        "\n",
        "encoder = Encoder(embedding_layer, latent_dim)\n",
        "print(\"Encoder model created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Va5oSsOcsxTF",
        "outputId": "233f7b67-383a-4d41-8b41-b2f86d3d67b9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder model created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# -------------------------------\n",
        "# 5. Define Classifier (Decoder)\n",
        "# -------------------------------\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, latent_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(latent_dim, output_dim)\n",
        "\n",
        "    def forward(self, hidden_state):\n",
        "        # hidden_state shape: (batch_size, latent_dim)\n",
        "        return self.fc(hidden_state)\n",
        "        # returned shape: (batch_size, output_dim)\n",
        "\n",
        "classifier = Classifier(latent_dim, output_dim)\n",
        "print(\"Classifier model created.\")\n",
        "\n",
        "# -------------------------------\n",
        "# 6. Combine Encoder and Classifier\n",
        "# -------------------------------\n",
        "class SentimentClassifier(nn.Module):\n",
        "    def __init__(self, encoder, classifier):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.classifier = classifier\n",
        "\n",
        "    def forward(self, text):\n",
        "        hidden_state = self.encoder(text)\n",
        "        prediction = self.classifier(hidden_state)\n",
        "        return prediction\n",
        "\n",
        "model = SentimentClassifier(encoder, classifier)\n",
        "model.to(device) # Move model to the appropriate device (CPU or GPU)\n",
        "print(\"SentimentClassifier model created and moved to device.\")\n",
        "\n",
        "# -------------------------------\n",
        "# 7. Define Loss Function and Optimizer\n",
        "# -------------------------------\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "print(\"Loss function and Optimizer defined.\")\n",
        "\n",
        "# -------------------------------\n",
        "# 8. Training Loop\n",
        "# -------------------------------\n",
        "def train(model, dataloader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for labels, text in tqdm(dataloader, desc=\"Training\"):\n",
        "        labels = labels.to(device)\n",
        "        text = text.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(text)\n",
        "        loss = criterion(predictions, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "    return epoch_loss / len(dataloader)\n",
        "\n",
        "# -------------------------------\n",
        "# 9. Evaluation Loop\n",
        "# -------------------------------\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    correct_predictions = 0\n",
        "    with torch.no_grad():\n",
        "        for labels, text in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            labels = labels.to(device)\n",
        "            text = text.to(device)\n",
        "\n",
        "            predictions = model(text)\n",
        "            loss = criterion(predictions, labels)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            # Calculate accuracy\n",
        "            _, predicted = torch.max(predictions, 1)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    return epoch_loss / len(dataloader), correct_predictions / len(dataloader.dataset)\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# 10. Train the model\n",
        "# -------------------------------\n",
        "N_EPOCHS = 5 # You can adjust the number of epochs\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    train_loss = train(model, train_dataloader, optimizer, criterion, device)\n",
        "    valid_loss, valid_acc = evaluate(model, test_dataloader, criterion, device)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'best-model.pt')\n",
        "        print(f\"Epoch {epoch+1}: Validation loss improved. Saving model.\")\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.3f}, Val Loss: {valid_loss:.3f}, Val Acc: {valid_acc:.3f}\")\n",
        "\n",
        "print(\"\\nTraining finished.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563,
          "referenced_widgets": [
            "9261e9c72def434f9859cd07a21697e9",
            "f2245abd72d14c84919c9805ab315e7d",
            "8227457109b54fdbb13b5a94fe8a3d91",
            "7bbe3f38c65a42b9a05b6ad1d929af1b",
            "893553eab1b44de3a8671b86f314b6e0",
            "f8691a7b377b4dcb8fb9166769725f04",
            "2c6e07e7ce5c49628e5a41d67bf795e2",
            "9f15a681da0e4f57b314c37af676c96d",
            "50a0f787ad88462ba4ed8d01aa96341d",
            "a47beb355a5e4a25becce085b0c06a4c",
            "cc4d606701ea4ddaadf3be8dc96319b2",
            "743332b8686549e0bd80f09407f5ec9a",
            "6f58743550594afdbd7e91ce5ad6f40a",
            "f3eefc951a65468b91418789aae9a3f0",
            "01a98cc1f96c4987b351fe968ddf1234",
            "567e748ebcc94e0da562d013d2dec21e",
            "a03c3f6a8af54ac7824867e16746dc37",
            "7a299892883844e086c32bfc5ef672a9",
            "0d1d2652f50c48db82e84574683da1bb",
            "83dc4d8f583341a6ba6afb4fbe8a64d8",
            "a40598d0a8ad420cbe88719e8df1bd0b",
            "b37cfbf38732480ea36a8c542765bf7d",
            "cb568392b0bc437ba300bf582be034aa",
            "9eb00f8031ac491a9cb8cfbf244660d8",
            "baa31e6580e94ba9a174dd75f0d92d9f",
            "7fe0bb53e9c34d0192ddbdbb0b563367",
            "c1c6bcdb55e6405fb3ca8319133134aa",
            "f5dced4ed41f46c38bcb3255944d7c7c",
            "5096eaabca64490690ed8f60f0544aa6",
            "5a181ae4dd0a430d87b85acf0667322e",
            "88d332f8494f4aa49e89cb0570bd7105",
            "f4f7e69c57874f978a3a0b576c000d38",
            "a8aafac4951c409ba3a2b4ba56379092",
            "72e0f1f457874a51a10d9fc62a56fda7",
            "2656f72e4add4cf79ce3fc17f9c03ddb",
            "8099b0f312f94ead84a124dae2320e48",
            "c1bd1296fa6549d1a9e9b5e8ab680b1e",
            "9e57363f1a3049fdb6d7662613dd1a3b",
            "3373c4f65b3940179acc5f6ecd1bb5a1",
            "a8b6c3297edc43e495ef7ba42dc5bd84",
            "28030ddb3a9f4965a4a173802f704155",
            "8620f02235904147b9b91f92af6f8a57",
            "bab997fdd7e446fe8f739add3917d6b8",
            "3d4811f21f6348e6a6047c5b3f0f12ac",
            "1a2693972bc04a369f53aee2f66c18c5",
            "125a6842f2274aa39eb65eb136b96b7e",
            "4a1ab53248f640c7903f7a9330fd3a1c",
            "cee83f6283db4508b64d39893c535a6a",
            "ce1142209f2544a492ae8138f1d14b44",
            "22a201498aeb47ffa3ef46c0d9579da1",
            "7dac9fa0cc714d23b29a5a6aba00c45d",
            "9489b7cd200648018e12b0e711af8e2e",
            "47cc4d6de5b0436c9cbb7190b2150444",
            "7339be95ad184b74993a861027c9231b",
            "f33c624da055401eb7227ea4ec6f2e9e",
            "67275a2c29164915bcaf119983f5a734",
            "376acae607d14033b74cae30e9a8c364",
            "8237f3eea72c498786c9752c015c524e",
            "634f9d1f0ea04113b4fe01a715a30aed",
            "20cbe91a151f4a64871ddd17dd9140db",
            "312b9528f6fe4db6816d70b2a3e74218",
            "6813db7d6cf5426984b18390a9945f29",
            "a16390c87db14d64a324faf1d7ad104d",
            "a2e9a53f6ac44b5faf41627b0f471560",
            "6625fe3bcff34f2fa1c4b0c873dd37bc",
            "c6208e25583d41b7bb2c0e9add18b572",
            "165417a20131492cafc329446a2b167a",
            "0baf9ba4db7c4b22a63ddc7b5db09b8e",
            "619f8e8381974d6590bcc63c863556b6",
            "181145fe3e584aa08d104f14fc3bec3e",
            "4fdcf76f3bb44191ac59a9bec466fde1",
            "8137d7468a934de9b989d52d6f0aea3e",
            "3a0e11ba10024468b2acb5a92c59bd81",
            "e29e9276d9444a10a4f74612c68d6be5",
            "67b64607ef734d19af275e6ea87c74b7",
            "d1f75994a79a461b932ef388dddf2677",
            "3fab27dbb0a6416fa097edf833d6c0fb",
            "ff214f47bdab41769e6a6c62b1532ca0",
            "4e9837cd9b994873a61a2e9be63abe13",
            "b651556b5ce04764add27a368f17a407",
            "de7fd0a3cce7401f85c8582e2b803466",
            "c3d3578b4f624821beba5eeb9d8ab91c",
            "09ec86d06ba84d83aa58283a5a8d4596",
            "f5a781e98c944182815c37f353aff202",
            "48fd3634ccc946f3a6301e9744dd782c",
            "76e2b443357640869e2e4f793abd75e1",
            "d38bcaab65df49e8b837088a17a23ac8",
            "965d020f95fa442a83261191314cbecc",
            "5eae46db820d4664b39038304ef063db",
            "2023687ea4e749d1bc04287faef93684",
            "5f9fca65c4a942d59060fd1cdde6a6b0",
            "c8ccb15de5d440f8a8c27e59a1d5f79f",
            "50bbd5926c5d42498889fa05ffb8132a",
            "8940e1ab776f4d23834ee200ae7a3e88",
            "7aeb9d4905864a2c8f63c3e28b7b417d",
            "0a75ed2110784f1fa608f2dfcddb9876",
            "4776557823cf4ff68875eeabd40d0c45",
            "705ef0be8a4044c495af31dd6833cbf2",
            "683a4f730c8a4cba93f6bfbda8570511",
            "c568f1f218b34d0cb81d991fc9b80230",
            "b664563371df4e509932d57619097a19",
            "a4820bfdc7144c65a2bdea278a66a4d2",
            "f741ea6442bc45389649633a534a8d5b",
            "11aa092fa02d459bb245a5a67795abe2",
            "055a9e09b3324a1891e83176cf6d806f",
            "a30e4fb792654bfabc8103b321221ca6",
            "73c25efbed954e5cad5f77c5455949f6",
            "074742556e594255b6a5f3760934c434",
            "bdb393aa1b1f49888ef4dc38c960eb72",
            "750a953023744f62a3427cfcac57b827"
          ]
        },
        "id": "mmfqqnCVtEq-",
        "outputId": "87dfa863-7ab2-4e13-afad-178b8282f8cb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier model created.\n",
            "SentimentClassifier model created and moved to device.\n",
            "Loss function and Optimizer defined.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training:   0%|          | 0/391 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9261e9c72def434f9859cd07a21697e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating:   0%|          | 0/391 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "743332b8686549e0bd80f09407f5ec9a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Validation loss improved. Saving model.\n",
            "Epoch 1: Train Loss: 0.702, Val Loss: 0.708, Val Acc: 0.520\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training:   0%|          | 0/391 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb568392b0bc437ba300bf582be034aa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating:   0%|          | 0/391 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72e0f1f457874a51a10d9fc62a56fda7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Validation loss improved. Saving model.\n",
            "Epoch 2: Train Loss: 0.704, Val Loss: 0.690, Val Acc: 0.529\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training:   0%|          | 0/391 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1a2693972bc04a369f53aee2f66c18c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating:   0%|          | 0/391 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67275a2c29164915bcaf119983f5a734"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Validation loss improved. Saving model.\n",
            "Epoch 3: Train Loss: 0.695, Val Loss: 0.687, Val Acc: 0.545\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training:   0%|          | 0/391 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "165417a20131492cafc329446a2b167a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating:   0%|          | 0/391 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff214f47bdab41769e6a6c62b1532ca0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train Loss: 0.683, Val Loss: 0.702, Val Acc: 0.529\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training:   0%|          | 0/391 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5eae46db820d4664b39038304ef063db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluating:   0%|          | 0/391 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c568f1f218b34d0cb81d991fc9b80230"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train Loss: 0.649, Val Loss: 0.701, Val Acc: 0.564\n",
            "\n",
            "Training finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Load the best trained model\n",
        "# ---------------------------\n",
        "model.load_state_dict(torch.load(\"best-model.pt\", map_location=device))\n",
        "model.eval()\n",
        "\n",
        "# ---------------------------\n",
        "# Example samples\n",
        "# ---------------------------\n",
        "samples = {\n",
        "    \"Positive\": \"This was the best movie I have ever seen.\",\n",
        "    \"Negative\": \"This was the worst movie I have ever watched.\",\n",
        "    \"Neutral\": \"The movie was okay, not great but not terrible.\",\n",
        "    \"Sarcasm\": \"Wow, this was such a masterpiece... the actors, the screenplay, I could stay for hours if it wasn't for how bad it was.\",\n",
        "    \"Irony\": \"The plot was so riveting, I couldn’t stop yawning.\"\n",
        "}\n",
        "\n",
        "# ---------------------------\n",
        "# Helper function to convert text to tensor\n",
        "# ---------------------------\n",
        "def text_to_tensor(text, vocab, max_seq_len, pad_idx):\n",
        "    tokens = text.split()\n",
        "    indexed_tokens = [vocab[token] for token in tokens[:max_seq_len]]\n",
        "    # Pad the sequence\n",
        "    padded_sequence = indexed_tokens + [pad_idx] * (max_seq_len - len(indexed_tokens))\n",
        "    return torch.tensor(padded_sequence, dtype=torch.int64)\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Predict function\n",
        "# ---------------------------\n",
        "def predict(text, model, vocab, max_seq_len, pad_idx, device):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        tensor = text_to_tensor(text, vocab, max_seq_len, pad_idx).unsqueeze(0).to(device) # shape: (1, seq_len)\n",
        "        prediction = model(tensor)               # shape: (1, num_classes)\n",
        "        predicted_label = torch.argmax(prediction, dim=1).item()\n",
        "    return predicted_label, prediction\n",
        "\n",
        "# ---------------------------\n",
        "# Run predictions\n",
        "# ---------------------------\n",
        "for label, text in samples.items():\n",
        "    # Pass vocab, max_seq_len, and pad_idx to the predict function\n",
        "    pred_label, raw_logits = predict(text, model, vocab, max_seq_len, pad_idx, device)\n",
        "    print(f\"{label} → Predicted class: {pred_label}, Raw logits: {raw_logits}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fu6pDqXXZZXe",
        "outputId": "46cb952c-9e63-4203-96e9-d754aed306d6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive → Predicted class: 1, Raw logits: tensor([[-1.2465, -0.6908]])\n",
            "Negative → Predicted class: 1, Raw logits: tensor([[-1.2465, -0.6908]])\n",
            "Neutral → Predicted class: 1, Raw logits: tensor([[-1.2465, -0.6908]])\n",
            "Sarcasm → Predicted class: 1, Raw logits: tensor([[-1.2465, -0.6908]])\n",
            "Irony → Predicted class: 1, Raw logits: tensor([[-1.2465, -0.6908]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[m for m in model.modules()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMUjgOthzZKQ",
        "outputId": "312ebca4-e6ec-43fb-ebac-dcf55c731856"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SentimentClassifier(\n",
              "   (encoder): Encoder(\n",
              "     (embedding): Embedding(25000, 150, padding_idx=1)\n",
              "     (rnn): RNN(150, 512, batch_first=True)\n",
              "   )\n",
              "   (classifier): Classifier(\n",
              "     (fc): Linear(in_features=512, out_features=2, bias=True)\n",
              "   )\n",
              " ),\n",
              " Encoder(\n",
              "   (embedding): Embedding(25000, 150, padding_idx=1)\n",
              "   (rnn): RNN(150, 512, batch_first=True)\n",
              " ),\n",
              " Embedding(25000, 150, padding_idx=1),\n",
              " RNN(150, 512, batch_first=True),\n",
              " Classifier(\n",
              "   (fc): Linear(in_features=512, out_features=2, bias=True)\n",
              " ),\n",
              " Linear(in_features=512, out_features=2, bias=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}
