{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlWkDVrsgSpiVY47OmrEVn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zamanmiraz/DSandML-Notebooks/blob/main/RAG/02_embedding_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "kSB5SsGNNr07"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/guyernest/advanced-rag.git\n",
        "%cd advanced-rag\n",
        "!pip install --upgrade -r requirements.txt\n",
        "# Install a compatible version of torchvision to address the nms error\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision==0.18.0\n",
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "mPS77AyxP1_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rich.console import Console\n",
        "from rich.style import Style\n",
        "import pathlib\n",
        "from rich_theme_manager import Theme, ThemeManager\n",
        "\n",
        "THEMES = [\n",
        "    Theme(\n",
        "        name=\"dark\",\n",
        "        description=\"Dark mode theme\",\n",
        "        tags=[\"dark\"],\n",
        "        styles={\n",
        "            \"repr.own\": Style(color=\"#e87d3e\", bold=True),      # Class names\n",
        "            \"repr.tag_name\": \"dim cyan\",                        # Adjust tag names\n",
        "            \"repr.call\": \"bright_yellow\",                       # Function calls and other symbols\n",
        "            \"repr.str\": \"bright_green\",                         # String representation\n",
        "            \"repr.number\": \"bright_red\",                        # Numbers\n",
        "            \"repr.none\": \"dim white\",                           # None\n",
        "            \"repr.attrib_name\": Style(color=\"#e87d3e\", bold=True),    # Attribute names\n",
        "            \"repr.attrib_value\": \"bright_blue\",                 # Attribute values\n",
        "            \"default\": \"bright_white on black\"                  # Default text and background\n",
        "        },\n",
        "    ),\n",
        "    Theme(\n",
        "        name=\"light\",\n",
        "        description=\"Light mode theme\",\n",
        "        styles={\n",
        "            \"repr.own\": Style(color=\"#22863a\", bold=True),          # Class names\n",
        "            \"repr.tag_name\": Style(color=\"#00bfff\", bold=True),     # Adjust tag names\n",
        "            \"repr.call\": Style(color=\"#ffff00\", bold=True),         # Function calls and other symbols\n",
        "            \"repr.str\": Style(color=\"#008080\", bold=True),          # String representation\n",
        "            \"repr.number\": Style(color=\"#ff6347\", bold=True),       # Numbers\n",
        "            \"repr.none\": Style(color=\"#808080\", bold=True),         # None\n",
        "            \"repr.attrib_name\": Style(color=\"#ffff00\", bold=True),  # Attribute names\n",
        "            \"repr.attrib_value\": Style(color=\"#008080\", bold=True), # Attribute values\n",
        "            \"default\": Style(color=\"#000000\", bgcolor=\"#ffffff\"),   # Default text and background\n",
        "        },\n",
        "    ),\n",
        "]\n",
        "\n",
        "theme_dir = pathlib.Path(\"themes\").expanduser()\n",
        "theme_dir.expanduser().mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "theme_manager = ThemeManager(theme_dir=theme_dir, themes=THEMES)\n",
        "theme_manager.list_themes()\n",
        "\n",
        "dark = theme_manager.get(\"dark\")\n",
        "theme_manager.preview_theme(dark)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "fJTooRhXPyqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rich.console import Console\n",
        "\n",
        "dark = theme_manager.get(\"dark\")\n",
        "light = theme_manager.get(\"light\")\n",
        "\n",
        "console = Console(theme=light)"
      ],
      "metadata": {
        "id": "zSMg91IuS40w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "EP18sAFOenkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_sentence = \"I have no interest in politics\""
      ],
      "metadata": {
        "id": "NYHnYRRSfk8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gemini Embedding\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "result = genai.embed_content(\n",
        "    model=\"models/text-embedding-004\",\n",
        "    content=first_sentence)\n",
        "\n",
        "print(result['embedding'])"
      ],
      "metadata": {
        "id": "a_FiWwf2jTDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "OO_2y9HZRABA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_sentence = \"I have no interest in politics\"\n",
        "second_sentence = \"The bank's interest rate is too high\""
      ],
      "metadata": {
        "id": "Bc2_tOy0Shui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_first_sentence = model.tokenize([first_sentence])\n",
        "console.rule(f\"{first_sentence}\")\n",
        "console.print(tokenized_first_sentence)"
      ],
      "metadata": {
        "id": "oIMJMKQuSvKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_second_sentence = model.tokenize([second_sentence])\n",
        "console.rule(f\"{second_sentence}\")\n",
        "console.print(tokenized_second_sentence)"
      ],
      "metadata": {
        "id": "MwyZM94nTn7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokens = (\n",
        "    model.tokenizer.convert_ids_to_tokens(tokenized_first_sentence['input_ids'][0]),\n",
        "    model.tokenizer.convert_ids_to_tokens(tokenized_second_sentence['input_ids'][0])\n",
        ")\n",
        "console.rule(\"Tokens\")\n",
        "console.print(sentence_tokens)"
      ],
      "metadata": {
        "id": "PES4LFoOU57q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = model._first_module().tokenizer.get_vocab().items()\n",
        "console.rule(\"Vocabulary\")\n",
        "console.print(list(vocabulary)[:20])"
      ],
      "metadata": {
        "id": "Tx7gOrpDS_xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_vocabulary = sorted(vocabulary, key=lambda x:x[1])\n",
        "sorted_tokens = [token for token, cnt in sorted_vocabulary]\n",
        "focused_token = 'interest'\n",
        "index = sorted_tokens.index(\"interest\")\n",
        "console.print(sorted_tokens[index - 10 : index + 10])"
      ],
      "metadata": {
        "id": "rFMv-0Y1T7GZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "console.print(model)"
      ],
      "metadata": {
        "id": "VgF4x4mKYdBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_module = model._first_module()\n",
        "console.print(first_module.auto_model)"
      ],
      "metadata": {
        "id": "pYRzRFHBY6h4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = first_module.auto_model.embeddings\n",
        "console.print(embeddings)"
      ],
      "metadata": {
        "id": "gQAwWV_8ZNqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ms = [m for m in model]\n",
        "len(ms), ms[0]"
      ],
      "metadata": {
        "id": "C9lHxvupkwZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"mps\" if torch.has_mps else \"cpu\")  # Use MPS for Apple, CUDA for others, or fallback to CPU\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Tokenize both texts\n",
        "    first_tokens = model.tokenize([first_sentence])\n",
        "    second_tokens = model.tokenize([second_sentence])\n",
        "\n",
        "    # Get the corresponding embeddings\n",
        "    first_embeddings = embeddings.word_embeddings(\n",
        "        first_tokens[\"input_ids\"].to(device)\n",
        "    )\n",
        "    second_embeddings = embeddings.word_embeddings(\n",
        "        second_tokens[\"input_ids\"].to(device)\n",
        "    )\n",
        "\n",
        "console.print(first_embeddings.shape, second_embeddings.shape)"
      ],
      "metadata": {
        "id": "_NcqLdy3lPFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import util\n",
        "import altair as alt\n",
        "import pandas as pd\n",
        "\n",
        "distances = util.cos_sim(first_embeddings.squeeze(), second_embeddings.squeeze()).cpu().numpy()\n",
        "\n",
        "# Get token labels\n",
        "x_labels = model.tokenizer.convert_ids_to_tokens(second_tokens[\"input_ids\"][0])\n",
        "y_labels = model.tokenizer.convert_ids_to_tokens(first_tokens[\"input_ids\"][0])\n",
        "\n",
        "# Create a DataFrame for Altair\n",
        "data = pd.DataFrame(\n",
        "    [(x, y, distances[i, j]) for i, y in enumerate(y_labels) for j, x in enumerate(x_labels)],\n",
        "    columns=['x', 'y', 'similarity']\n",
        ")\n",
        "\n",
        "# Create heatmap using Altair\n",
        "chart = alt.Chart(data).mark_rect().encode(\n",
        "    x=alt.X('x:O', title='Second Sentence Tokens', axis=alt.Axis(labelAngle=-45), sort=x_labels),\n",
        "    y=alt.Y('y:O', title='First Sentence Tokens', sort=y_labels),\n",
        "    color=alt.Color('similarity:Q', scale=alt.Scale(scheme='yellowgreenblue')),\n",
        "    tooltip=['x', 'y', alt.Tooltip('similarity:Q', format='.2f')]\n",
        ").properties(\n",
        "    width=500,\n",
        "    height=400,\n",
        "    title='Input Token Similarity Heatmap'\n",
        ")\n",
        "\n",
        "# Add text labels\n",
        "text = chart.mark_text(baseline='middle').encode(\n",
        "    text=alt.Text('similarity:Q', format='.2f'),\n",
        "    color=alt.condition(\n",
        "        alt.datum.similarity > 0.5,\n",
        "        alt.value('white'),\n",
        "        alt.value('black')\n",
        "    )\n",
        ")\n",
        "\n",
        "# Combine chart and text\n",
        "final_chart = (chart + text).configure_title(fontSize=16)\n",
        "\n",
        "# Display the chart\n",
        "final_chart\n"
      ],
      "metadata": {
        "id": "0W-pN-kol2MJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_embeddings = first_module.auto_model \\\n",
        "    .embeddings \\\n",
        "    .word_embeddings \\\n",
        "    .weight \\\n",
        "    .detach() \\\n",
        "    .cpu() \\\n",
        "    .numpy()\n",
        "\n",
        "console.print(token_embeddings.shape)"
      ],
      "metadata": {
        "id": "ezP_32Z-p_DY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "tsne = TSNE(n_components=2, metric=\"cosine\", random_state=42)\n",
        "tsne_embeddings_2d = tsne.fit_transform(token_embeddings)\n",
        "console.print(tsne_embeddings_2d.shape)"
      ],
      "metadata": {
        "id": "XhsOnRMMqGVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_colors = []\n",
        "for token in sorted_tokens:\n",
        "    if token[0] == \"[\" and token[-1] == \"]\": # Control Tokens\n",
        "        token_colors.append(\"red\")\n",
        "    elif token.startswith(\"##\"):            # Suffix Tokens\n",
        "        token_colors.append(\"blue\")\n",
        "    else:\n",
        "        token_colors.append(\"green\")        # All Word Tokens"
      ],
      "metadata": {
        "id": "BgoshSJSyObx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import altair as alt\n",
        "import pandas as pd\n",
        "\n",
        "# Enable VegaFusion data transformer to handle larger datasets\n",
        "alt.data_transformers.enable(\"vegafusion\")\n",
        "\n",
        "# Create a DataFrame from the data\n",
        "df = pd.DataFrame({\n",
        "    'x': tsne_embeddings_2d[:, 0],\n",
        "    'y': tsne_embeddings_2d[:, 1],\n",
        "    'token': sorted_tokens,\n",
        "    'color': token_colors\n",
        "})\n",
        "\n",
        "# Create the Altair chart\n",
        "chart = alt.Chart(df).mark_circle(size=30).encode(\n",
        "    x='x:Q',\n",
        "    y='y:Q',\n",
        "    color=alt.Color('color:N', scale=None),\n",
        "    tooltip=['token:N']\n",
        ").properties(\n",
        "    width=600,\n",
        "    height=900,\n",
        "    title='Token Embeddings'\n",
        ").interactive()\n",
        "\n",
        "# Display the chart\n",
        "chart"
      ],
      "metadata": {
        "id": "D7uaUoHlyRPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_embedding = model.encode([first_sentence])\n",
        "console.print(output_embedding.shape)"
      ],
      "metadata": {
        "id": "0ul2zP2WyqNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_embedding = model.encode([first_sentence])\n",
        "console.print(output_embedding.shape)"
      ],
      "metadata": {
        "id": "DQ0J4g-Pz6m9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_token_embeddings = model.encode(\n",
        "    [first_sentence],\n",
        "    output_value=\"token_embeddings\"\n",
        ")\n",
        "console.print(output_token_embeddings[0].shape)"
      ],
      "metadata": {
        "id": "z6n4vedV0AYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    first_tokens = model.tokenize([first_sentence])\n",
        "    second_tokens = model.tokenize([second_sentence])\n",
        "\n",
        "    first_output_embeddings = model.encode(\n",
        "        [first_sentence],\n",
        "        output_value=\"token_embeddings\"\n",
        "    )\n",
        "    second_output_embeddings = model.encode(\n",
        "        [second_sentence],\n",
        "        output_value=\"token_embeddings\"\n",
        "    )\n",
        "\n",
        "# Calculate cosine similarity\n",
        "distances = util.cos_sim(\n",
        "    first_output_embeddings[0],\n",
        "    second_output_embeddings[0]\n",
        ")"
      ],
      "metadata": {
        "id": "VVbOhXEb0fbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get token labels\n",
        "x_labels = model.tokenizer.convert_ids_to_tokens(second_tokens[\"input_ids\"][0])\n",
        "y_labels = model.tokenizer.convert_ids_to_tokens(first_tokens[\"input_ids\"][0])\n",
        "\n",
        "# Create a DataFrame for Altair\n",
        "data = pd.DataFrame(\n",
        "    [(x, y, distances[i, j]) for i, y in enumerate(y_labels) for j, x in enumerate(x_labels)],\n",
        "    columns=['x', 'y', 'similarity']\n",
        ")\n",
        "\n",
        "# Create heatmap using Altair\n",
        "chart = alt.Chart(data).mark_rect().encode(\n",
        "    x=alt.X('x:O', title='Second Sentence Tokens', axis=alt.Axis(labelAngle=-45), sort=x_labels),\n",
        "    y=alt.Y('y:O', title='First Sentence Tokens', sort=y_labels),\n",
        "    color=alt.Color('similarity:Q', scale=alt.Scale(scheme='yellowgreenblue', domain=[0, 1])),\n",
        "    tooltip=['x', 'y', alt.Tooltip('similarity:Q', format='.2f')]\n",
        ").properties(\n",
        "    width=500,\n",
        "    height=400,\n",
        "    title='Output Token Similarity Heatmap'\n",
        ")\n",
        "\n",
        "# Add text labels\n",
        "text = chart.mark_text(baseline='middle').encode(\n",
        "    text=alt.Text('similarity:Q', format='.2f'),\n",
        "    color=alt.condition(\n",
        "        alt.datum.similarity > 0.5,\n",
        "        alt.value('white'),\n",
        "        alt.value('black')\n",
        "    )\n",
        ")\n",
        "\n",
        "# Combine chart and text\n",
        "final_chart = (chart + text).configure_title(fontSize=16)\n",
        "\n",
        "# Display the chart\n",
        "final_chart"
      ],
      "metadata": {
        "id": "D7l0nkUE0rdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calculate cosine distance between output embeddings\n",
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "from rich.panel import Panel\n",
        "from rich.table import Table\n",
        "\n",
        "def calculate_sentence_similarity(first_sentence, second_sentence):\n",
        "\n",
        "    first_embeddings = model.encode([first_sentence])\n",
        "    second_embeddings = model.encode([second_sentence])\n",
        "\n",
        "    # Reshape the embeddings to 2D arrays\n",
        "    first_embedding_2d = first_embeddings.reshape(1, -1)\n",
        "    second_embedding_2d = second_embeddings.reshape(1, -1)\n",
        "\n",
        "    # Calculate cosine distance\n",
        "    cosine_distance = cosine_distances(first_embedding_2d, second_embedding_2d)[0][0]\n",
        "\n",
        "    # Note: Cosine distance is 1 - cosine similarity\n",
        "    cosine_similarity = 1 - cosine_distance\n",
        "\n",
        "    console.print(\n",
        "        Panel(\n",
        "            f\"[cyan bold]First Sentence:[/cyan bold] {first_sentence}\\n\"\n",
        "            f\"[cyan bold]Second Sentence:[/cyan bold] {second_sentence}\",\n",
        "            title=\"[green bold]Similarity Calculation[/green bold]\",\n",
        "            expand=False,\n",
        "            border_style=\"dim white\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "    results = Table(title=\"Results\")\n",
        "    results.add_column(\"Metric\", style=\"bold\")\n",
        "    results.add_column(\"Value\", style=\"bold\")\n",
        "    results.add_row(\"Cosine Distance\", f\"{cosine_distance:.4f}\", style=\"cyan\")\n",
        "    results.add_row(\"Cosine Similarity\", f\"{cosine_similarity:.4f}\", style=\"bright_yellow\")\n",
        "\n",
        "    console.print(results)"
      ],
      "metadata": {
        "id": "GYMHXzGg1h03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_sentence_similarity(first_sentence, second_sentence)"
      ],
      "metadata": {
        "id": "-qIinmEe1nrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "third_sentence = \"Chase increased its lending fees\"\n",
        "\n",
        "calculate_sentence_similarity(second_sentence, third_sentence)"
      ],
      "metadata": {
        "id": "wG_q2O6Z1tfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "\n",
        "improved_model = transformers.AutoModel.from_pretrained(\"jxm/cde-small-v1\", trust_remote_code=True)\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "yXCncGlu7fWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "console.print(improved_model)"
      ],
      "metadata": {
        "id": "nnOzTBem7wau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "corpus = load_dataset(\"BeIR/fiqa\", \"corpus\")[\"corpus\"]\n",
        "queries = load_dataset(\"BeIR/fiqa\", \"queries\")[\"queries\"]"
      ],
      "metadata": {
        "id": "-lkb9M9_8vXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "\n",
        "console.rule(\"Corpus Sample\")\n",
        "print(tabulate(\n",
        "    corpus\n",
        "    .to_pandas()\n",
        "    .head(10)\n",
        "    .assign(text_start=lambda x: x['text'].str[:100])\n",
        "    .drop(columns=['text','title'])\n",
        "    ,headers='keys',\n",
        "    tablefmt='github',\n",
        "    showindex=False\n",
        "))"
      ],
      "metadata": {
        "id": "sWZB7JEU80xX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "console.rule(\"Queries Sample\")\n",
        "print(tabulate(\n",
        "    queries\n",
        "    .to_pandas()\n",
        "    .head(10)\n",
        "    .assign(text_start=lambda x: x['text'].str[:100])\n",
        "    .drop(columns=['text','title'])\n",
        "    ,headers='keys',\n",
        "    tablefmt='github',\n",
        "    showindex=False\n",
        "))"
      ],
      "metadata": {
        "id": "5HPazPMM84TM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_prefix = \"search_query: \"\n",
        "document_prefix = \"search_document: \""
      ],
      "metadata": {
        "id": "OvRuEtw486h_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def process_ex_document(ex: dict) -> dict:\n",
        "  ex[\"text\"] = f\"{ex['title']} {ex['text']}\"\n",
        "  return ex\n",
        "\n",
        "corpus_size = improved_model.config.transductive_corpus_size\n",
        "console.print(f\"Choosing {corpus_size} out of {len(corpus)} documents\")\n",
        "minicorpus_docs = corpus.select(random.choices(list(range(len(corpus))), k=corpus_size))\n",
        "minicorpus_docs = minicorpus_docs.map(process_ex_document)[\"text\"]\n",
        "minicorpus_docs = tokenizer(\n",
        "    [document_prefix + doc for doc in minicorpus_docs],\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=512,\n",
        "    return_tensors=\"pt\"\n",
        ")"
      ],
      "metadata": {
        "id": "cDywa22w89W9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "device = torch.device(\"mps\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "minicorpus_docs = minicorpus_docs.to(device)"
      ],
      "metadata": {
        "id": "7bTKM9g0ErPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "dataset_embeddings = []\n",
        "for i in tqdm(range(0, len(minicorpus_docs[\"input_ids\"]), batch_size)):\n",
        "    minicorpus_docs_batch = {k: v[i:i+batch_size] for k,v in minicorpus_docs.items()}\n",
        "    with torch.no_grad():\n",
        "        dataset_embeddings.append(\n",
        "            improved_model.first_stage_model(**minicorpus_docs_batch)\n",
        "        )\n",
        "\n",
        "dataset_embeddings = torch.cat(dataset_embeddings)"
      ],
      "metadata": {
        "id": "5tHncKBVEtYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_docs = corpus.select(range(16)).map(process_ex_document)[\"text\"]\n",
        "\n",
        "docs_tokens = tokenizer(\n",
        "    [document_prefix + doc for doc in sample_docs],\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=512,\n",
        "    return_tensors=\"pt\"\n",
        ").to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "  doc_embeddings = improved_model.second_stage_model(\n",
        "      input_ids=docs_tokens[\"input_ids\"],\n",
        "      attention_mask=docs_tokens[\"attention_mask\"],\n",
        "      dataset_embeddings=dataset_embeddings,\n",
        "  )\n",
        "doc_embeddings /= doc_embeddings.norm(p=2, dim=1, keepdim=True)"
      ],
      "metadata": {
        "id": "XuX-ZOIwJh7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries_sample = queries.select(range(16))[\"text\"]\n",
        "queries_tokens = tokenizer(\n",
        "    [query_prefix + query for query in queries_sample],\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=512,\n",
        "    return_tensors=\"pt\"\n",
        ").to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "  query_embeddings = improved_model.second_stage_model(\n",
        "      input_ids=queries_tokens[\"input_ids\"],\n",
        "      attention_mask=queries_tokens[\"attention_mask\"],\n",
        "      dataset_embeddings=dataset_embeddings,\n",
        "  )\n",
        "query_embeddings /= query_embeddings.norm(p=2, dim=1, keepdim=True)"
      ],
      "metadata": {
        "id": "e4zXXgORKgmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  doc_basic_embeddings = model.encode(sample_docs)"
      ],
      "metadata": {
        "id": "hCCH0WtTLRKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  queries_basic_embeddings = model.encode(queries_sample)"
      ],
      "metadata": {
        "id": "2-okyGkiLUIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
        "\n",
        "# Heatmap for improved model\n",
        "sns.heatmap((doc_embeddings @ query_embeddings.T).cpu(), cmap=\"jet\", ax=ax1, vmin=0, vmax=1)\n",
        "ax1.set_title(\"Improved Model\", fontsize=16)\n",
        "\n",
        "# Heatmap for basic model\n",
        "sns.heatmap((doc_basic_embeddings @ queries_basic_embeddings.T), cmap=\"jet\", ax=ax2 ,vmin=0, vmax=1)\n",
        "ax2.set_title(\"Basic Model\", fontsize=16)\n",
        "\n",
        "plt.tight_layout()\n",
        "console.rule(\"Embedding Model Comparison\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NIRfA6ONLXbk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}