{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO02he86jYa2VoAXvzImwFc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zamanmiraz/DSandML-Notebooks/blob/main/RAG/04_contextual_retrieval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfrCHwpD_jhK"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/guyernest/advanced-rag.git\n",
        "%cd advanced-rag\n",
        "!pip install --upgrade -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision==0.18.0\n",
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "zW-ua86l5JV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rich.console import Console\n",
        "from rich.style import Style\n",
        "import pathlib\n",
        "from rich_theme_manager import Theme, ThemeManager\n",
        "\n",
        "THEMES = [\n",
        "    Theme(\n",
        "        name=\"dark\",\n",
        "        description=\"Dark mode theme\",\n",
        "        tags=[\"dark\"],\n",
        "        styles={\n",
        "            \"repr.own\": Style(color=\"#e87d3e\", bold=True),      # Class names\n",
        "            \"repr.tag_name\": \"dim cyan\",                        # Adjust tag names\n",
        "            \"repr.call\": \"bright_yellow\",                       # Function calls and other symbols\n",
        "            \"repr.str\": \"bright_green\",                         # String representation\n",
        "            \"repr.number\": \"bright_red\",                        # Numbers\n",
        "            \"repr.none\": \"dim white\",                           # None\n",
        "            \"repr.attrib_name\": Style(color=\"#e87d3e\", bold=True),    # Attribute names\n",
        "            \"repr.attrib_value\": \"bright_blue\",                 # Attribute values\n",
        "            \"default\": \"bright_white on black\"                  # Default text and background\n",
        "        },\n",
        "    ),\n",
        "    Theme(\n",
        "        name=\"light\",\n",
        "        description=\"Light mode theme\",\n",
        "        styles={\n",
        "            \"repr.own\": Style(color=\"#22863a\", bold=True),          # Class names\n",
        "            \"repr.tag_name\": Style(color=\"#00bfff\", bold=True),     # Adjust tag names\n",
        "            \"repr.call\": Style(color=\"#ffff00\", bold=True),         # Function calls and other symbols\n",
        "            \"repr.str\": Style(color=\"#008080\", bold=True),          # String representation\n",
        "            \"repr.number\": Style(color=\"#ff6347\", bold=True),       # Numbers\n",
        "            \"repr.none\": Style(color=\"#808080\", bold=True),         # None\n",
        "            \"repr.attrib_name\": Style(color=\"#ffff00\", bold=True),  # Attribute names\n",
        "            \"repr.attrib_value\": Style(color=\"#008080\", bold=True), # Attribute values\n",
        "            \"default\": Style(color=\"#000000\", bgcolor=\"#ffffff\"),   # Default text and background\n",
        "        },\n",
        "    ),\n",
        "]\n",
        "\n",
        "theme_dir = pathlib.Path(\"themes\").expanduser()\n",
        "theme_dir.expanduser().mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "theme_manager = ThemeManager(theme_dir=theme_dir, themes=THEMES)\n",
        "theme_manager.list_themes()\n",
        "\n",
        "dark = theme_manager.get(\"dark\")\n",
        "theme_manager.preview_theme(dark)\n",
        "light = theme_manager.get(\"light\")\n",
        "\n",
        "console = Console(theme=light)"
      ],
      "metadata": {
        "id": "L8XCXOFa7UEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"jamescalam/ai-arxiv2\", split=\"train\")\n",
        "console.print(dataset)"
      ],
      "metadata": {
        "id": "CcDvjxEH6tcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict\n",
        "import google.generativeai as genai\n",
        "from semantic_chunkers import StatisticalChunker\n",
        "from google.colab import userdata\n",
        "import logging\n",
        "\n",
        "logging.disable(logging.CRITICAL)\n",
        "\n",
        "# Configure API\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "class GeminiEncoder(dict):\n",
        "    def __init__(self, model_name=\"models/text-embedding-004\", score_threshold=0.3):\n",
        "        super().__init__(name=model_name, score_threshold=score_threshold)\n",
        "        self.model_name=model_name\n",
        "    def __call__(self, docs):\n",
        "        return [genai.embed_content(model=self.model_name, content=doc)[\"embedding\"]\n",
        "                for doc in docs]\n",
        "\n",
        "encoder = GeminiEncoder()\n",
        "\n",
        "chunker = StatisticalChunker(\n",
        "    encoder = encoder,\n",
        "    min_split_tokens=100,\n",
        "    max_split_tokens=500\n",
        ")\n"
      ],
      "metadata": {
        "id": "e4QJxj_-7nEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks_0 = chunker(docs=[dataset[\"content\"][0]])"
      ],
      "metadata": {
        "id": "qE1Jv5FvCaWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rich.text import Text\n",
        "from rich.panel import Panel\n",
        "\n",
        "chunk_0_0 = ' '.join(chunks_0[0][0].splits)\n",
        "\n",
        "content = Text(chunk_0_0)\n",
        "console.print(Panel(content, title=f\"Chunk 0\", expand=False, border_style=\"bold\"))"
      ],
      "metadata": {
        "id": "2LHjWrSWCut0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "from google.colab import userdata\n",
        "\n",
        "# --- PROMPTS ---\n",
        "DOCUMENT_CONTEXT_PROMPT = \"\"\"\n",
        "<document>\n",
        "{doc_content}\n",
        "</document>\n",
        "\"\"\"\n",
        "\n",
        "CHUNK_CONTEXT_PROMPT = \"\"\"\n",
        "Here is the chunk we want to situate within the whole document\n",
        "<chunk>\n",
        "{chunk_content}\n",
        "</chunk>\n",
        "\n",
        "Please give a short succinct context to situate this chunk within the overall document\n",
        "for the purposes of improving search retrieval of the chunk.\n",
        "Answer only with the succinct context and nothing else.\n",
        "\"\"\"\n",
        "\n",
        "# --- CREATE CLIENT (pass API key here) ---\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# --- FUNCTION ---\n",
        "def situate_context(doc: str, chunk: str) -> str:\n",
        "    model = \"models/gemini-2.0-flash-001\"  # Must include version suffix\n",
        "\n",
        "    # ✅ Create cache\n",
        "    cache = client.caches.create(\n",
        "        model=model,\n",
        "        config=types.CreateCachedContentConfig(\n",
        "            display_name=\"document_context_cache\",\n",
        "            system_instruction=(\n",
        "                \"You are helping generate semantic context for document chunks \"\n",
        "                \"to improve retrieval accuracy.\"\n",
        "            ),\n",
        "            contents=[\n",
        "                {\"role\": \"user\", \"parts\": [{\"text\": DOCUMENT_CONTEXT_PROMPT.format(doc_content=doc)}]}\n",
        "            ],\n",
        "            ttl=\"300s\",\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    # ✅ Use cache\n",
        "    response = client.models.generate_content(\n",
        "        model=model,\n",
        "        contents=[\n",
        "            {\"role\": \"user\", \"parts\": [{\"text\": CHUNK_CONTEXT_PROMPT.format(chunk_content=chunk)}]},\n",
        "        ],\n",
        "        config=types.GenerateContentConfig(cached_content=cache.name),\n",
        "    )\n",
        "\n",
        "    return response.text.strip()\n"
      ],
      "metadata": {
        "id": "eea6Q4lJEQXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_context = situate_context(dataset[\"content\"][0], chunk_0_0)"
      ],
      "metadata": {
        "id": "gKK-PiYPFYFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "console.print(chunk_context)"
      ],
      "metadata": {
        "id": "z6heQfz_IeXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arxiv_id = dataset[0][\"id\"]\n",
        "refs = list(dataset[0][\"references\"].values())\n",
        "doc_text = dataset[0][\"content\"]\n",
        "title = dataset[0][\"title\"]\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "corpus_json = []\n",
        "for i, chunk in tqdm(enumerate(chunks_0[0]), total=len(chunks_0[0]), desc=\"Processing chunks\"):\n",
        "    chunk_text = ' '.join(chunk.splits)\n",
        "    contextualized_text = situate_context(doc_text, chunk_text).text\n",
        "    corpus_json.append({\n",
        "        \"id\": i,\n",
        "        \"text\": f\"{chunk_text}\\n\\n{contextualized_text}\",\n",
        "        \"metadata\" : {\n",
        "            \"title\": title,\n",
        "            \"arxiv_id\": arxiv_id,\n",
        "            \"references\": refs\n",
        "        }\n",
        "    })"
      ],
      "metadata": {
        "id": "8EwPikTGJa1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# Create the data directory if it doesn't exist\n",
        "os.makedirs('data', exist_ok=True)\n",
        "\n",
        "with open('data/corpus.json', 'w') as f:\n",
        "    json.dump(corpus_json, f)"
      ],
      "metadata": {
        "id": "Q5y_Fj82L8bG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}